# PySpark
• Installation Windows/Linux
• Pyspark - Architecture
• SparkSession, RDD, Parallelize
• repartition() vs coalesce()
• Accumulator & Broadcast Variables
# PySpark DataFrame
• Create a DataFrame,
• Convert RDD to DataFrame
• StructType & StructField
• Row Class, Column Class
• select(), collect(), withColumn()
• withColumnRenamed()
• where() & filter()
• drop() & dropDuplicates()
• orderBy(), sort(), groupBy(), join()
• union() & unionAll(), unionByName()
• UDF (User Defined Function)
• map(), flatMap(), foreach()
• sample() vs sampleBy(), fillna() & fill()
• pivot() (Row to Column)
• partitionBy(), ArrayType Column (Array)
• MapType (Map/Dict)
# PySpark SQL Functions
• Aggregate Functions
• Window Functions
• Date and Timestamp Functions
# PySpark Built-In Functions
when(), expr(), lit(), split(), concat_ws()
• substring(), translate(), regexp_replace()
• overlay(), to_timestamp(), to_date()
• date_format(), datediff()
• months_between(), explode()
• array_contains(), array(), collect_list()
• collect_set(), create_map(), map_keys()
• map_values(), struct(), countDistinct()
• sum(), avg(), row_number(),rank()
• dense_rank(), percent_rank()
• typedLit(), from_json(), to_json()
• json_tuple(), get_json_object()
• schema_of_json()
